---
layout: post
title: "데이터베이스 인터널스: 5장 트랜잭션 처리와 복구"
categories: [Database]
tags: [Database, Reading]
---

책 데이터베이스 인터널스는 데이터베이스가 내부적으로 어떻게 동작하는지 설명해주는 책이다. 각 설명에 대한 논문 등 레퍼런스들도 잘 명시되어 있어서, 내용의 신뢰도가 높다.

이 책의 5장을 읽으며 이해한 내용을 정리하였다.

> 전에 한 번 읽었던 책인데 표시를 안 해두니 어떤 문장을 주의깊게 읽었는지, 어떤 질문이 있었는지 기억이 나지 않는다. 책에 밑줄이나 포스트잇 등 표시를 하는 대신 이 포스트에 정리해보기로 했다.

---

트랜잭션은 DBMS의 논리적 작업 단위이다. 트랜잭션은 ACID 4가지 속성을 보장한다.

- Atomicity(원자성): 트랜잭션의 결과는 전체 성공(커밋) or 전체 실패(rollback) 둘 중 하나만 존재한다. 부분 성공은 존재하지 않는다.
- Consistency(일관성): 트랜잭션은 참조 무결성 등의 제약조건을 위반하지 않고 다음 유효한 상태로 변경된다. 데이터베이스가 아닌 사용자가 제어할 수 있는 유일한 속성이다.
- Isolation(격리성): 트랜잭션은 다른 트랜잭션으로부터 격리되어 트랜잭션끼리 서로 간섭할 수 없다. 
- Durability(지속성): 시스템 중단 또는 장애가 발생해도 디스크의 트랜잭션 커밋 상태는 유지돼야 한다.

트랜잭션을 수행하려면 디스크에 저장되는 자료 구조 외에도 여러 컴포넌트가 필요하다

- 트랜잭션 매니저
- 잠금 매니저
- 페이지 캐시
- 로그 매니저

## 버퍼 관리 (페이지 캐시)

영구 저장소(디스크) 접근은 메모리보다 느림 -> 성능에 악영향 -> 이 접근 횟수를 줄이기 위해 페이지 캐시 사용

페이지 캐시는 디스크보다 작기 때문에 새로운 페이지 추가 시 기존 페이지 만료가 필요하다

> 커널 페이지 캐시 우회 기법: 많은 DBMS들이 O_DIRECT 플래그를 사용해 파일을 읽는다. 이를 통해 DB 특화된 페이지 캐시 관리 기법을 사용할 수 있다.

## 캐싱

페이지가 변경된 경우 페이지에 더티 플래그를 설정한다. 더티 플래그는 해당 페이지가 디스크와 동기화되지 않았고 Durability를 위해 디스크로 flush되어야 함을 의미한다.

## 캐시 만료

새로운 페이지를 저장하기 위해 오래된 페이지는 제거해야 한다.

하지만 페이지를 제거할 때마다 디스크로 flush한다면 성능을 저하시킬 수 있다. 따라서 일부 DBMS는 별도의 백그라운드 프로세스가 더티 페이지를 주기적으로 디스크로 flush한다.

Durability는 매우 중요한 속성이다. 이를 보장하기 위해 (데이터 손실 방지) 체크포인트 프로세스가 flush 시점을 제어한다.

체크포인트 프로세스는 WAL(Write-Ahead Log)와 페이지 캐시의 sync가 맞도록 조정한다. flush가 완료된 페이지 관련 로그는 WAL에서 삭제될 수 있다.

## 페이지 고정

B-트리의 상위 노드는 대부분의 읽기 작업에서 접근한다. 이 노드들을 캐시해두면 성능에 큰 도움이 된다.

자주 사용되는 페이지는 고정(pinning)시킬 수 있다. pinning은 페이지를 캐시에 고정해두는 것이다.

## 페이지 교체 알고리즘

캐시된 페이지는 eviction policy(페이지 교체 알고리즘)에 따라 캐시에서 제거된다. 페이지 교체 알고리즘은 페이지 캐시 성능을 결정하는 중요한 요인이다.

캐시 용량을 늘리면 제거되는 페이지가 줄어들까? 벨레이디의 모순 (Belady\s anomaly) 현상은 적합하지 않은 페이지 교체 알고리즘 사용 시 페이지 수가 증가하면 제거되느 페이지 수도 같이 증가하는 현상을 의미한다.

페이지 교체 알고리즘들

- FIFO (가장 먼저 들어온 것부터): First In First Out, 페이지 ID를 삽입 순서대로 큐에 추가한다. 먼저 캐시된 페이지부터 제거한다.
- LRU (가장 오래 전에 사용한 것부터): Least-Recently Used, FIFO와 마찬가지로 큐에 추가하지만 페이지가 재요청되면 다시 큐에 추가한다. (처음 페이징된 것처럼)
  - 페이지 요청 시마다 갱신이 필요하므로 동시 접근 환경에서는 비효율적일 수 있다.
  - LRU 기반의 2Q LRU, LRU-K 알고리즘도 있다.
- CLOCK: LRU의 대안으로 더 단순하고 캐시 친화적, 동시성을 지원한다. 리눅스는 변형된 CLOCK을 사용한다.
  - CLOCK-sweep은 페이지에 대한 참조와 접근 여부 비트를 원형 버퍼에 저장한다. 페이지가 요청될 때마다 접근 비트를 1로 설정한다. 원형 버퍼를 순회하며 접근 비트를 확인한다.
  - 접근 비트가 0이면 해당 페이지를 제거 대상으로 선정하고 만료 작업을 스케줄링한다.
  - LRU가 최적의 페이지 교체 알고리즘은 아니다. 예를 들어 부하가 높은 DB에서 최신성(recency)은 데이터가 요청된 순서일 뿐이기 때문이다.
- LFU (가장 사용빈도가 낮은 것부터): Least-Frequently Used, 요청 빈도가 낮은 페이지부터 제거한다. TinyLFU라는 Java Caffeine 라이브러리에서 사용하는 알고리즘이 있다.
  - TinyLFU는 3개의 큐에 페이지를 저장한다: admission, probation, protected

## 복구

WAL(선행 기록 로그, 커밋 로그)는 장애 및 트랜잭션 복구를 위해 디스크에 저장하는 append-only 보조 자료 구조이다.

페이지 캐시의 내용이 디스크로 flush되기 전까지 작업 이력의 유일한 복사본은 WAL이다. PostgreSQL, MySQL 등 많은 DB에서 사용한다.

WAL의 주요 기능

- 페이지의 변경사항을 캐시에 버퍼링하는 동시에 Durability를 보장한다
- 페이지 변경사항이 flush되기 전에 먼저 디스크에 로깅한다.
- 장애 발생 시 로그를 기반으로 마지막 메모리 상태를 재구성한다.

## 로그의 시맨틱

WAL은 append-only 자료 구조이고 로그는 immutable(불변)하기 때문에 모든 쓰기 작업은 순차적이다.

따라서 write 작업이 새로운 로그를 추가하는동안 다른 read 작업은 특정 최신 값까지 안전하게 읽을 수 있다.

WAL은 여러 로그 레코드로 구성되어 있고, 모든 레코드는 단조 증가하는 LSB(Log Sequence Number)를 가진다.

WAL 로그 레코드들은 로그 버퍼에 임시 저장하고 force 작업 시 디스크로 flush된다. force 작업은 로그 버퍼가 가득차거나 요청에 의해 수행된다.

WAL은 체크포인트에 도달하면 이전 로그를 정리(trimming)한다. 체크포인트는 해당 시점 이전의 모든 로그 레코드가 flush되어 더이상 필요하지 않음을 의미한다. 이를 통해 데이터베이스 가동 시 수행할 작업의 양을 대폭 줄인다.

모든 데이터를 한번에 디스크로 flush하면, 다른 모든 작업들이 중지되어야 한다. 이 문제를 해결하기 위해 fuzzy 체크포인트를 사용한다.

## 작업 로그 대 데이터 로그

System R의 durability, atomicity 속성 구현

copy-on-write, shadow paging: 새로운 데이터를 shadow page에 write하고 페이지 포인터를 그 페이지로 변경한다.

모든 상태 변화는 이전 상태와 이후 상태의 조합으로 나타낼 수 있다. (위와 같이)

또는 그에 대응되는 redo, undo 작업으로 나타낼 수 있다.

physical log vs logical log

- physical log(데이터 로그): 전체 페이지 상태 또는 바이트별 변경사항
  - 수행 전후의 상태를 모두 저장함. 대상 작업에 영향받은 모든 페이지를 참조해야 함.
- logical log(작업 로그): 현재 상태에 수행해야 하는 작업
  - e.g. "Y 키에 레코드 X 삽입" (redo 작업) or "Y 키 값 삭제" (undo 작업)

대부분 DBMS는 물리적 로그와 논리적 로그를 모두 사용함

- undo: 논리적 로그 (작업 로그) -> 동시성과 성능 타겟
- redo: 물리적 로그 (데이터 로그) -> 복구 시간 단축

## 스틸 / 포스 정책

캐시에 저장된 변경사항의 flush 시점 결정하기 위한 아래 정책들

- steal vs no-steal
- force vs no-force

페이지 캐시와 직접 연관 있지만 복구 복구 알고리즘 선택에 큰 영향을 미침.

- steal: 트랜잭션이 수정한 dirty page를 언제든지(커밋하기 전이라도) flush 허용 (다른 페이지를 메모리로 paging하기 위해)
- force: 트랜잭션 커밋 시 dirty page를 모두 flush

> dirty page: 디스크로 flush되지 않은 변경된 페이지

> 이해를 돕기 위한 참고 문서
> - <https://stackoverflow.com/a/37861999/12956829>
> - <https://d2.naver.com/helloworld/407507>

steal과 force는 트랜잭션의 redo, undo와 관련있기 때문에 매우 중요하다. undo는 force된 페이지를 rollback하고 redo는 커밋된 트랜잭션을 다시 수행한다.

- no-steal: 디스크에는 이전 상태의 페이지가 저장돼있고 로그에는 최신 변경사항이 저장돼있음 -> redo 로그만 사용해 상태 복구 가능
- no-force: flush 시점을 늦추면 더 많은 변경사항 버퍼링 가능. 하지만 더 오래 캐시해야 하므로 더 큰 페이지 캐시가 필요할 수 있음.

force 정책을 사용하면 장애 복구 시 트랜잭션 커밋 결과를 재구성할 필요 없음. 하지만 많은 I/O로 인해 latency가 증가함.

트랜잭션의 dirty page가 flush되면 rollback 가능하도록 커밋할 때까지 undo 관련 정보를 로그에 유지해야 한다. flush되지 않았다면 redo 레코드를 로그에 유지해야 한다.

## ARIES

ARIES는 steal/no-force 기반 복구 알고리즘. 빠른 복구를 위해 physical redo + 일반 작업 동시성을 위해 logical undo(페이지에 독립적으로 적용 가능)를 사용함

복구 시 커밋되지 않은 트랜잭션을 undo하기 전에 DB 상태 재구성을 위해 WAL 레코드 기반 작업을 재수행 (repeating history), undo 중에 보상 로그 레코드를 기록한다.

> (번역본 132p 중) 보상 로그 레코드 (CLR, Compensation Log Record): 트랜잭션 롤백 또는 복구 중 장애가 발생해도 시스템이 계속해서 정상 작동할 수 있도록 보상 로그 레코드를 로그에 저장하고 undo 작업 시 사용한다.

장애 발생 후 DBMS 재시작 시 복구 과정 3단계

1. 분석(analysis) 단계
   - 페이지 캐시에 저장된 dirty page, 당시 수행 중이던 트랜잭션 목록 파악.
   - dirty page 정보 기반으로 redo 단계 시작 지점을 결정.
   - 트랜잭션 목록은 undo 단계에서 미완료 트랜잭션 롤백 시 사용.
2. redo 단계
   - 장애 발생 전까지의 작업을 재수행. 데이터베이스를 이전 상태로 복원.
   - 불완전한 트랜잭션 뿐만 아니라 커밋됐지만 flush되지 않은 트랜잭션 rollback을 위한 준비 단계.
3. undo 단계
   - 불완전한 트랜잭션 rollback, 마지막 consistent 상태로 복원.
   - 모든 작업은 실제 수행 순서의 역순으로 rollback.
   - 복구 중에도 장애가 발생할 수 있으므로 undo 작업도 로그에 기록해야 함.

ARIES는 dirty page 테이블을 관리하고, physical redo, logical undo, fuzzy checkpoint를 사용한다. 이 알고리즘의 기본 개념은 오늘날에도 트랜잭션 처리와 복구에 그대로 사용되고 있다.

## 동시성 제어

DBMS 구조 절에서 동시성은 Tx 매니저와 Lock 매니저가 제어한다고 언급함.

동시성 제어는 여러 트랜잭션 사이의 상호작용을 제어하는 기법이다.

동시성 제어의 분류:

- OCC(Optimistic Concurrency Control, 낙관적 동시성 제어)
  - 여러 트랜잭션이 동시에 read/write 허용
  - 결합된 여러 작업이 직렬화 가능한지(serializable) 여부를 결정
  - 트랜잭션이 서로 간섭하지 않고 각자의 작업 내역을 유지할 수 있게 함. 커밋 전에 충돌이 발생할 수 있는지 확인. 충돌 발생 시 트랜잭션 하나를 중단.
- MVCC(Multiversion Concurrency Control, 다중 버전 동시성 제어)
  - 여러 버전의 레코드를 저장, 과거 특정 타임스탬프(시점)의 DB 일관성 보장.
  - 구현: 하나의 트랜잭션만을 채택하는 검증 기법을 사용 또는 timestamp ordering, lockless 방식 또는 two-phase locking과 같은 잠금 기반 방식으로도 구현 가능
- PCC(Pessimistic Concurrency Control, 비관적 동시성 제어)
  - 잠김 기반 & 무잠금 기반 방식이 있고 공유 자원에 대한 관리 및 접근 방식이 다름.
  - 잠금 방식: 트랜잭션이 레코드에 대한 잠금을 획득, 다른 레코드는 동시에 접근 불가능.
  - 무잠금 방식: read/write 작업 목록을 유지하고 완료되지 않은 트랜잭션의 스케줄에 따라 다른 트랜잭션의 수행을 제한. 트랜잭션들이 서로의 잠금 해제를 기다리는 deadlock(교착 상태) 발생 가능

## 직렬화 가능성

- DB 맥락의 스케줄: read, write, commit 등의 상태 변경 작업 목록
- complete schedule: 모든 작업
- correct schedule: ACID 보장 시 일부 병렬 수행 or 수행 순서 바뀔 수 있음
- serial schedule: 모든 트랜잭션이 교차하지 않음

트랜잭션 하나씩 실행 -> throughput 크게 저하

Solution: serializable schedule

## 트랜잭션 격리

여러 isolation level 지원. 이 수준은 수행 중 발생 가능한 이상 현상(anomaly)을 나타냄.

## read/write anomaly

SQL standard의 read anomaly

- dirty read: 커밋되지 않은 다른 트랜잭션의 결과를 읽음
- non-repeatable read: 동일 로우를 2번 쿼리 시 결과가 다름 (중간에 다른 트랜잭션에서 커밋함)
- phantom read: 범위 쿼리로 여러 로우를 2번 쿼리 시 결과가 다름. (phantom 레코드가 포함됨)

write anomaly

- lost update: 동시 수정으로 인해 앞의 update가 덮어씌워짐
- dirty write: dirty read한 값을 수정, 커밋
- write skew(쓰기 치우침): 개별 트랜잭션은 불변 조건을 충족하지만 동시 수행 시 조건이 위반되는 현상
  - 대표적인 예시가 계좌에서 두 트랜잭션이 동시 인출

## 격리 수준

- 격리 수준의 종류
- 분산 시스템 맥락의 linearizability와 serializability의 차이
- 일부 DBMS에서 지원하는 snapshot isolation 수준을 언급

## 낙관적 동시성 제어

트랜잭션 충돌이 거의 발생하지 않는다고 가정함

일반적으로 트랜잭션 수행은 3단계로 구성됨

- 읽기 단계
- 검증 단계
- 쓰기 단계



## Reference

- 책: <https://www.yes24.com/Product/Goods/97015247>

